# Core ML frameworks for Linux with CUDA (RTX 4090)
# Install PyTorch with CUDA support first:
# pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# Note: Install PyTorch with CUDA first using the command above, then:
# pip install -r requirements-linux.txt

# Transformers and model utilities
transformers>=4.40.0
datasets>=2.14.0
accelerate>=0.27.0

# ONNX export and optimization
optimum[exporters]>=1.17.0
onnx>=1.15.0
onnxruntime-gpu>=1.17.0

# Data processing and evaluation
scikit-learn>=1.3.0
pandas>=2.0.0
numpy>=1.24.0

# Utilities
tqdm>=4.66.0
pyyaml>=6.0.0

# Optional: for better training
sentencepiece>=0.1.99
protobuf>=4.25.0

# GPU monitoring (optional but recommended)
nvidia-ml-py3>=7.352.0

# GGUF export (for LM Studio deployment on macOS)
# Note: llama.cpp must be installed separately (handled by pipeline scripts)
# See: https://github.com/ggerganov/llama.cpp
